{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/habiburrahamanfahim/classifying-radio-signals-using-pytorch?scriptVersionId=145148814\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Introdution**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Import PyTorch and related modules\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Import torchvision transformations\nfrom torchvision import transforms as T\n\n# Import a popular image model library\nimport timm","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:00.637142Z","iopub.execute_input":"2023-10-03T21:29:00.639921Z","iopub.status.idle":"2023-10-03T21:29:00.648763Z","shell.execute_reply.started":"2023-10-03T21:29:00.63986Z","shell.execute_reply":"2023-10-03T21:29:00.647529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **First Image**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# The path to the image that has been uploaded\n\n# USED LOCAL DATA PATH AS IT CREATES ERROR ON KAGGLE NOTEBOOK ENV\n#image_path = \"C:/Users/Asus/Desktop/Coursera/Classify Radio Signals with PyTorch/Project/Project/Untitled-design.png\"\n\nimage_path = \"/kaggle/input/radio-signals-dataset/Untitled-design.png\"\n\n# Load and display the image\nimg = mpimg.imread(image_path)\n\n# Set the figure size to HD resolution\n\n# Set the size to 10 inches by 10 inches\nplt.figure(figsize=(10, 10)) \n\nplt.imshow(img)\n\n# Turn off axes\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:00.713218Z","iopub.execute_input":"2023-10-03T21:29:00.714062Z","iopub.status.idle":"2023-10-03T21:29:01.377245Z","shell.execute_reply.started":"2023-10-03T21:29:00.714009Z","shell.execute_reply":"2023-10-03T21:29:01.376085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Configurations**","metadata":{}},{"cell_type":"code","source":"# Paths to the training and validation CSV files\n\n# USED LOCAL DATA PATH AS IT CREATES ERROR ON KAGGLE NOTEBOOK ENV\n#TRAIN_CSV = 'C:/Users/Asus/Desktop/Coursera/Classify Radio Signals with PyTorch/Project/Project/train.csv'\n#VALID_CSV = 'C:/Users/Asus/Desktop/Coursera/Classify Radio Signals with PyTorch/Project/Project/valid.csv'\n\nTRAIN_CSV = \"/kaggle/input/radio-signals-dataset/train.csv\"\nVALID_CSV = \"/kaggle/input/radio-signals-dataset/train.csv\"\n\n# Batch size for training and validation data\nBATCH_SIZE = 128\n\n# Device to use for training ('cpu' for CPU, 'cuda' for GPU if available)\nDEVICE = 'cpu'\n\n# Name of the pre-trained model architecture to use\nMODEL_NAME = 'efficient_b0'\n\n# Learning rate for the optimizer\nLR = 0.001\n\n# Number of training epochs\nEPOCHS = 15","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:01.379435Z","iopub.execute_input":"2023-10-03T21:29:01.379775Z","iopub.status.idle":"2023-10-03T21:29:01.3849Z","shell.execute_reply.started":"2023-10-03T21:29:01.379746Z","shell.execute_reply":"2023-10-03T21:29:01.384185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_CSV)\ndf_valid = pd.read_csv(VALID_CSV)\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:01.386174Z","iopub.execute_input":"2023-10-03T21:29:01.386453Z","iopub.status.idle":"2023-10-03T21:29:19.184436Z","shell.execute_reply.started":"2023-10-03T21:29:01.386429Z","shell.execute_reply":"2023-10-03T21:29:19.183346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"No. of examples present in df_train : {len(df_train)}\")\nprint(f\"No. of examples present in df_valid : {len(df_valid)}\")\nprint(f\"Labels are : {df_train['labels'].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.185768Z","iopub.execute_input":"2023-10-03T21:29:19.186512Z","iopub.status.idle":"2023-10-03T21:29:19.19463Z","shell.execute_reply.started":"2023-10-03T21:29:19.186483Z","shell.execute_reply":"2023-10-03T21:29:19.193547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 3100 # Index No.\n\nrow = df_train.iloc[idx]\n\n# row = df_valid.iloc[idx]\n\n# Converting a specific row data from 'train.csv' dataset into image\nimage_pixels = np.array(row[0:8192], dtype = np.float64)\nlabel = row.labels\n\nimage = np.resize(image_pixels, (64, 128)) # 64*128 = 8192\n\nplt.imshow(image)\nplt.title(label); # Here without ';' shows 'Text(0.5, 1.0, '[label]')'","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.198128Z","iopub.execute_input":"2023-10-03T21:29:19.198506Z","iopub.status.idle":"2023-10-03T21:29:19.534234Z","shell.execute_reply.started":"2023-10-03T21:29:19.198477Z","shell.execute_reply":"2023-10-03T21:29:19.532753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Declare Spec Augmentations**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# The path to the image that has been uploaded\n\n# USED LOCAL DATA PATH AS IT CREATES ERROR ON KAGGLE NOTEBOOK ENV\n#image_path = \"C:/Users/Asus/Desktop/Coursera/Classify Radio Signals with PyTorch/Project/Project/image6.png\"\n\nimage_path = \"/kaggle/input/radio-signals-dataset/image6.png\"\n\n\n# Load and display the image\nimg = mpimg.imread(image_path)\n\n# Set the figure size to HD resolution\n\n# Set the size to 10 inches by 10 inches\nplt.figure(figsize=(10, 10)) \n\nplt.imshow(img)\n\n# Turn off axes\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.536498Z","iopub.execute_input":"2023-10-03T21:29:19.537422Z","iopub.status.idle":"2023-10-03T21:29:19.781381Z","shell.execute_reply.started":"2023-10-03T21:29:19.537355Z","shell.execute_reply":"2023-10-03T21:29:19.780046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install spec_augment --install-option=\"--target=/kaggle/input/radio-signals-dataset/spec_augment.py\"","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.783063Z","iopub.execute_input":"2023-10-03T21:29:19.783684Z","iopub.status.idle":"2023-10-03T21:29:19.788733Z","shell.execute_reply.started":"2023-10-03T21:29:19.78365Z","shell.execute_reply":"2023-10-03T21:29:19.787621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Define your train transform function\n# from spec_augment import TimeMask, FreqMask\n# def get_train_transform():\n#     return T.Compose([\n#         TimeMask(T=15, num_masks=4),  # Use the imported TimeMask class\n#         FreqMask(F=15, num_masks=3)   # Use the imported FreqMask class\n#     ])\n\nimport torchvision.transforms as T\n\ndef get_train_transform():\n    return T.Compose([\n        T.RandomHorizontalFlip(),  # Randomly flip images horizontally\n        T.RandomVerticalFlip(),    # Randomly flip images vertically\n        T.RandomRotation(15),      # Randomly rotate images by up to 15 degrees\n        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color\n        T.RandomResizedCrop((64, 128), scale=(0.8, 1.0)),  # Random resized crop\n        # Remove the following line, as the data is already a PyTorch tensor\n        # T.ToTensor(),\n        T.Normalize(mean=[0.485], std=[0.229])  # Normalize image data\n    ])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.790447Z","iopub.execute_input":"2023-10-03T21:29:19.791011Z","iopub.status.idle":"2023-10-03T21:29:19.815398Z","shell.execute_reply.started":"2023-10-03T21:29:19.790968Z","shell.execute_reply":"2023-10-03T21:29:19.814094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Custom Dataset**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nclass SpecDataset(Dataset):\n    def __init__(self, df, augmentations=None):\n        self.df = df\n        self.augmentations = augmentations\n        \n        label_mapper = {\n            'Squiggle': 0,\n            'Narrowband': 1,\n            'Narrowbanddrd': 2,\n            'Noises': 3\n        }\n        \n        self.df['labels'] = self.df['labels'].map(label_mapper)\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_pixels = np.array(row[0:8192], dtype=np.float64)\n        \n        image = np.resize(image_pixels, (64, 128, 1))  # (h, w, c)\n        label = np.array(row['labels'], dtype=np.int64)\n        \n        image = torch.Tensor(image).permute(2, 0, 1)  # (c, h, w)\n        \n        if self.augmentations is not None:\n            image = self.augmentations(image)\n            \n        return image.float(), label\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.817099Z","iopub.execute_input":"2023-10-03T21:29:19.817491Z","iopub.status.idle":"2023-10-03T21:29:19.847825Z","shell.execute_reply.started":"2023-10-03T21:29:19.817458Z","shell.execute_reply":"2023-10-03T21:29:19.846853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = SpecDataset(df_train, get_train_transform())\nvalidset = SpecDataset(df_valid)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.849526Z","iopub.execute_input":"2023-10-03T21:29:19.850231Z","iopub.status.idle":"2023-10-03T21:29:19.870826Z","shell.execute_reply.started":"2023-10-03T21:29:19.850195Z","shell.execute_reply":"2023-10-03T21:29:19.869528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = trainset[591]\n\nplt.imshow(image.permute(0, 1 , 2).squeeze())\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:19.872604Z","iopub.execute_input":"2023-10-03T21:29:19.873252Z","iopub.status.idle":"2023-10-03T21:29:20.175042Z","shell.execute_reply.started":"2023-10-03T21:29:19.873167Z","shell.execute_reply":"2023-10-03T21:29:20.173414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Dataset into Batches**","metadata":{}},{"cell_type":"code","source":"trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\nvalidloader = DataLoader(validset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:20.176834Z","iopub.execute_input":"2023-10-03T21:29:20.177302Z","iopub.status.idle":"2023-10-03T21:29:20.185218Z","shell.execute_reply.started":"2023-10-03T21:29:20.177261Z","shell.execute_reply":"2023-10-03T21:29:20.183968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total no. of batches in trainloader : {len(trainloader)}\")\nprint(f\"Total no. of batches in validloader : {len(validloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:20.186664Z","iopub.execute_input":"2023-10-03T21:29:20.186992Z","iopub.status.idle":"2023-10-03T21:29:20.212302Z","shell.execute_reply.started":"2023-10-03T21:29:20.186953Z","shell.execute_reply":"2023-10-03T21:29:20.211021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, labels in trainloader:\n    break;\nprint(f\"One image batch shape : {images.shape}\")\nprint(f\"One label batch shape : {labels.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:20.216854Z","iopub.execute_input":"2023-10-03T21:29:20.217436Z","iopub.status.idle":"2023-10-03T21:29:21.080845Z","shell.execute_reply.started":"2023-10-03T21:29:20.217384Z","shell.execute_reply":"2023-10-03T21:29:21.079718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Model**","metadata":{}},{"cell_type":"code","source":"import timm\n\nclass SpecModel(nn.Module):\n    def __init__(self):\n        super(SpecModel, self).__init__()\n        MODEL_NAME = 'tf_efficientnet_b0'\n        self.net = timm.create_model(MODEL_NAME, num_classes=4, pretrained=True, in_chans=1)\n\n    def forward(self, images, labels = None):\n        \n        logits = self.net(images)\n        \n        if labels is not None:\n            loss = nn.CrossEntropyLoss()\n            return logits, loss(logits, labels)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:21.082341Z","iopub.execute_input":"2023-10-03T21:29:21.082657Z","iopub.status.idle":"2023-10-03T21:29:21.089786Z","shell.execute_reply.started":"2023-10-03T21:29:21.082631Z","shell.execute_reply":"2023-10-03T21:29:21.088304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SpecModel()\nmodel;","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:21.09181Z","iopub.execute_input":"2023-10-03T21:29:21.092242Z","iopub.status.idle":"2023-10-03T21:29:21.498168Z","shell.execute_reply.started":"2023-10-03T21:29:21.092207Z","shell.execute_reply":"2023-10-03T21:29:21.497008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Train and Eval Frunction**","metadata":{}},{"cell_type":"code","source":"pip install utils","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:21.499891Z","iopub.execute_input":"2023-10-03T21:29:21.500661Z","iopub.status.idle":"2023-10-03T21:29:31.742048Z","shell.execute_reply.started":"2023-10-03T21:29:21.500624Z","shell.execute_reply":"2023-10-03T21:29:31.740096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\n# Define the multiclass_accuracy function\ndef multiclass_accuracy(logits, labels):\n    \"\"\"\n    Calculate the multiclass accuracy given logits and true labels.\n    \n    Args:\n        logits (Tensor): Predicted logits from the model.\n        labels (Tensor): True labels.\n\n    Returns:\n        accuracy (float): Multiclass accuracy.\n    \"\"\"\n    # Calculate accuracy based on logits and labels\n    predicted_labels = torch.argmax(logits, dim=1)\n    correct_predictions = (predicted_labels == labels).sum().item()\n    total_predictions = labels.size(0)\n    \n    accuracy = correct_predictions / total_predictions\n    \n    return accuracy\n\ndef train_fn(model, dataloader, optimizer, current_epoch):\n    model.train()\n    total_loss = 0.0\n    total_acc = 0.0\n    progress_bar = tqdm(dataloader, desc=\"EPOCH [TRAIN] \" + str(current_epoch + 1) + '/' + str(EPOCHS))\n\n    for t, data in enumerate(progress_bar):\n        images, labels = data\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n        logits, loss = model(images, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_acc += multiclass_accuracy(logits, labels)  # Use the locally defined function\n\n        temp = {'loss': '%6.2f' % float(total_loss / (t + 1)), 'acc': '%6.4f' % float(total_acc / (t + 1))}\n\n        progress_bar.set_postfix(temp)\n\n    return total_loss / len(dataloader), total_acc / len(dataloader)\n\n\n# Generated by Codeium\n\n# def train_fn(model, dataloader, optimizer, current_epoch):\n#     model.train()\n#     train_loss = 0.0\n#     train_acc = 0.0\n\n#     for images, labels in dataloader:\n#         images = images.to(DEVICE)\n#         labels = labels.to(DEVICE)\n\n#         # Check the number of channels in the input images\n#         if images.size(1) != 3:\n#             # If the number of channels is not 3, repeat the single channel to create 3 channels\n#             images = images.repeat(1, 3, 1, 1)\n\n#         optimizer.zero_grad()\n#         logits, loss = model(images, labels)\n#         loss.backward()\n#         optimizer.step()\n\n#         train_loss += loss.item()\n#         train_acc += (logits.argmax(1) == labels).sum().item()\n\n#     return train_loss / len(dataloader), train_acc / len(dataloader.dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:31.744198Z","iopub.execute_input":"2023-10-03T21:29:31.74459Z","iopub.status.idle":"2023-10-03T21:29:31.756958Z","shell.execute_reply.started":"2023-10-03T21:29:31.744555Z","shell.execute_reply":"2023-10-03T21:29:31.755659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(model, dataloader, current_epoch):\n    model.eval()\n    total_loss = 0.0\n    total_acc = 0.0\n    progress_bar = tqdm(dataloader, desc=\"EPOCH [VALID] \" + str(current_epoch + 1) + '/' + str(EPOCHS))\n\n    with torch.no_grad():\n        for t, data in enumerate(progress_bar):\n            images, labels = data\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n            logits, loss = model(images, labels)\n\n            total_loss += loss.item()\n            total_acc += multiclass_accuracy(logits, labels)\n\n            temp = {'loss' : '%6f' %float(total_loss/(t+1)), 'acc' : '%6f' %float(total_acc/(t+1))}\n\n            progress_bar.set_postfix(temp)\n\n        return total_loss/len(dataloader), total_acc/len(dataloader)\n\n# Generated by Codeium\n\n# def valid_fn(model, dataloader, current_epoch):\n#     model.eval()\n#     total_loss = 0.0\n#     total_acc = 0.0\n\n#     with torch.no_grad():\n#         for images, labels in dataloader:\n#             images = images.to(DEVICE)\n#             labels = labels.to(DEVICE)\n\n#             # Check the number of channels in the input images\n#             if images.size(1) != 3:\n#                 # If the number of channels is not 3, repeat the single channel to create 3 channels\n#                 images = images.repeat(1, 3, 1, 1)\n\n#             logits, loss = model(images, labels)\n\n#             total_loss += loss.item()\n#             total_acc += (logits.argmax(1) == labels).sum().item()\n\n#     return total_loss / len(dataloader), total_acc / len(dataloader.dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:31.758647Z","iopub.execute_input":"2023-10-03T21:29:31.758991Z","iopub.status.idle":"2023-10-03T21:29:31.780071Z","shell.execute_reply.started":"2023-10-03T21:29:31.758951Z","shell.execute_reply":"2023-10-03T21:29:31.778583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training Loop**","metadata":{}},{"cell_type":"code","source":"def fit(model, trainloader, validloader, optimizer):\n    best_valid_loss = np.inf\n\n    for epoch in range(EPOCHS):\n        # Training\n        train_loss, train_acc = train_fn(model, trainloader, optimizer, epoch)\n        \n        # Validation\n        valid_loss, valid_acc = valid_fn(model, validloader, epoch)\n        \n        # Check if the current validation loss is the best so far\n        if valid_loss < best_valid_loss:\n            torch.save(model.state_dict(), MODEL_NAME + '-best-weight.pt')\n            print('SAVED-BEST-WEIGHTS')\n            best_valid_loss = valid_loss\n        \n        # Print epoch-wise statistics\n        print(f'Epoch [{epoch + 1}/{EPOCHS}]')\n        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n        print(f'Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}%')\n        print('-' * 50)\n\n# def fit(model, trainloader, validloader, optimizer):\n\n#     best_valid_loss = np.inf\n\n#     for i in range(EPOCHS):\n#         train_loss, train_acc = train_fn(model, trainloader, optimizer, i)\n#         valid_loss, valid_acc = valid_fn(model, validloader, i)\n        \n#         if valid_loss < best_valid_loss:\n#             torch.save(model.state_dict(), MODEL_NAME + '-best-weight.pt')\n#             print('SAVED-BEST-WEIGHTS')\n#             best_valid_loss = valid_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:31.781768Z","iopub.execute_input":"2023-10-03T21:29:31.782203Z","iopub.status.idle":"2023-10-03T21:29:31.797263Z","shell.execute_reply.started":"2023-10-03T21:29:31.782169Z","shell.execute_reply":"2023-10-03T21:29:31.796324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=LR)\nfit(model, trainloader, validloader, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:31.798694Z","iopub.execute_input":"2023-10-03T21:29:31.799289Z","iopub.status.idle":"2023-10-03T22:11:49.949555Z","shell.execute_reply.started":"2023-10-03T21:29:31.799256Z","shell.execute_reply":"2023-10-03T22:11:49.948365Z"},"trusted":true},"execution_count":null,"outputs":[]}]}